{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ztkFDmv7go3K",
        "PJ0NJSaw_kff",
        "keJ2jRIMsukf",
        "9CdzdV2js87V",
        "sGWwMI5bHBNo",
        "_q5bSDfZFPsu",
        "xsOUllZZFTBD",
        "xPojVh65hmgi",
        "SSmgUU2-MCXr",
        "sqMLxhPo3zHn",
        "S9RDTSPE33wp",
        "KS2aeyR6uxzF",
        "L7cga4FgvQe5",
        "jHS97QsozBxn",
        "_qr_RH0W-ptQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztkFDmv7go3K"
      },
      "source": [
        "#CSE/STAT 416 Quiz Section 5\n",
        "\n",
        "##Precision and Recall, Random Forests, Ensemble Methods\n",
        "February 9th, 2023\n",
        "\n",
        "Author: Anne Wagner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk73u17GhF_X"
      },
      "source": [
        "We have talked a bit about precision and recall, different types of classification error, and when certain types of error might be preferred. To help motivate this with an example, we will consider data on breast cancer scans by the University of Wisconsin.\n",
        "\n",
        "Data Source: UCI Machine Learning Repository http://archive.ics.uci.edu/ml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WF3m37igoOD"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "raw_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ0NJSaw_kff"
      },
      "source": [
        "The data we will be looking at consists of different metrics gathered from breast cancer biopsies. Typically our goal in classification to try and accurately classify all classes, but in this particular context it is important to consider the two types of errors.\n",
        "\n",
        "####Type 1 Error - False Positive\n",
        "In the context of cancer biopsies, a false positive will likely result in the patient seeking more tests to confirm before starting any treatment. This is not an ideal outcome, but we are more concerned with...\n",
        "\n",
        "####Type 2 Error - False Negative\n",
        "A false negative means a patient who does have breast cancer is being told that the test results were benign. This may lead to the patient ignoring the problem until it becomes worse or entirely untreatable. \n",
        "\n",
        "While we wish to avoid making either one of these misclassifications, the cost of each of these errors should be considered when choosing a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyUU5ajDbOsl"
      },
      "source": [
        "y=((raw_data[1]=='M')-.5)*2\n",
        "X=np.vstack((np.log(raw_data[14]),np.log(raw_data[23])))\n",
        "\n",
        "n=y.shape[0]\n",
        "inds=np.array(range(n))\n",
        "np.random.RandomState(416)\n",
        "np.random.shuffle(inds)\n",
        "\n",
        "y_train=y[inds[1:(n//2)]]\n",
        "y_test=y[inds[(n//2):n]]\n",
        "X_train=X[:,inds[1:(n//2)]]\n",
        "X_test=X[:,inds[(n//2):n]]\n",
        "\n",
        "mal=(y==1)\n",
        "mal_test=(y_test==1)\n",
        "mal_train=(y_train==1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdtNMAXH_i1U"
      },
      "source": [
        "In total there are 10 different metrics gathered about the biopsied cells, repeated on 3 perpendicular axes. For the purposes of this exercise, we are going to focus on just two of the variables, chosen to help visualize examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLauNlbI5_Z0"
      },
      "source": [
        "plt.scatter(np.exp(X[0,][mal]),np.exp(X[1,][mal]),marker='+',cmap=\"blue\")\n",
        "plt.scatter(np.exp(X[0,][~mal]),np.exp(X[1,][~mal]),marker='_',cmap=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8bfz72oCRi_"
      },
      "source": [
        "Again for the purposes visualization, we are going to convert the data to a log scale. This will have no effect on the classification via decision trees (and related methods). Why is that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keJ2jRIMsukf"
      },
      "source": [
        "#####Why that is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "294lGJ38s3Q2"
      },
      "source": [
        "Decision trees only branch on a single variable at a time and the logarithm function is one-to-one. A branch at $x<a$ is identical to a branch at $log(x)<log(a)$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CdzdV2js87V"
      },
      "source": [
        "####The scaled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_smC64tiUEy"
      },
      "source": [
        "plt.scatter(X[0,][mal],X[1,][mal],marker='+',c='cyan')\n",
        "plt.scatter(X[0,][~mal],X[1,][~mal],marker='_',c='orange')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRE9cLg0CHK5"
      },
      "source": [
        "We will use blue (cyan) to denote positive classification, and red (orange) to denote negative classificiation. While there are some regions that are clearly dominated by positive or negative values, there is still considerable overlap for many of the points.\n",
        "\n",
        "While we seek to minimize classification errors (more so false negatives) we need to consider metrics other than just accuracy, which doesn't account for the type of error, or error count, which doesn't account for the quantity of positive or negative values in the data. To that end we have two metrics to consider."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGWwMI5bHBNo"
      },
      "source": [
        "#Precision and Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48u1M7CJDYy4"
      },
      "source": [
        "Precision and recall both relate to the number of true positive observations, but calculate two different rates. \n",
        "\n",
        "*Precision* refers to the ability to ensure positives predictions are positive. With an algorithm that is very precise, you can be assured that most positive predictions are actually positive.\n",
        "\n",
        "$$Precision = \\frac{\\#\\text{True Positives}}{\\#\\text{True Positives} + \\#\\text{False Positives}}$$\n",
        "\n",
        "*Recall* refers to the ability to ensure that cases that are positive are predicted positively. With an algorithm with high recall, you can be assured that you will predict most positive cases correctly.\n",
        "\n",
        "$$Recall = \\frac{\\#\\text{True Positives}}{\\#\\text{True Positives} + \\#\\text{False Negatives}}$$\n",
        "\n",
        "In the context of this data set, which are we more concerned with, and why? \n",
        "\n",
        "Can we create a predictor that scores perfectly on that metric while still being useless?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q5bSDfZFPsu"
      },
      "source": [
        "#####Answer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8zX3_VmFSiu"
      },
      "source": [
        "We care more about our model having a high recall. That way we can ensure that anyone who does have breast cancer is properly informed. At the same time, we could just classify every case as malignant and achieve a recall of 1, but there is literally no point in taking that test as it offers no value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsOUllZZFTBD"
      },
      "source": [
        "#####Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfLuhYrgFrpU"
      },
      "source": [
        "Let's look at a simple decision tree on this data. We will use a depth of 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUuPMLCt5bVG"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "dtm = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
        "dtm.fit(X_train.T, y_train)\n",
        "grid=np.meshgrid(np.arange(-.5,3.2,.01),np.arange(2.4,4.0,.01))\n",
        "grid=np.vstack((grid[0].flatten(),grid[1].flatten()))\n",
        "\n",
        "\n",
        "print(np.array([['TN','FN'],['FP','TP']]))\n",
        "print(cm(y_train,dtm.predict(X_train.T)))\n",
        "\n",
        "out=dtm.predict_proba(grid.T).T[1]\n",
        "grid_colors=plt.cm.seismic((out-.5)*(-2))\n",
        "plt.scatter(grid[0,],grid[1,],marker='.',c=grid_colors,alpha=.25)\n",
        "plt.scatter(X_train[0,][mal_train],X_train[1,][mal_train],marker='+',c='cyan')\n",
        "plt.scatter(X_train[0,][~mal_train],X_train[1,][~mal_train],marker='_',c=\"orange\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNcuwqUHEDiU"
      },
      "source": [
        "Take a moment to try and calculate the precision and recall for this training data. Do you see evidence of overfitting in the results? (I certainly do, but the results keep changing from run to run! set.seed has failed me!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu1uwwZ8G72B"
      },
      "source": [
        "def print_prec_and_recall(y_true,y_pred):\n",
        "  cm_out=cm(y_true,y_pred)\n",
        "  #We can quickly calculate the precision and recall from the confusion matrix\n",
        "  print(np.array([['TN','FN'],['FP','TP']]))\n",
        "  print(cm_out)\n",
        "  print(\"Precision: \",np.round(cm_out[1,1]/(cm_out[1,1]+cm_out[0,1]),5),\"  Recall:\", np.round(cm_out[1,1]/(cm_out[1,1]+cm_out[1,0]),5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ5KYmt_LXBh"
      },
      "source": [
        "import matplotlib.colors as colors\n",
        "def error_scatter(X,mal,correct,grid,grid_colors,size=None):\n",
        "  if size is None:\n",
        "    plt.scatter(grid[0,],grid[1,],marker='.',c=grid_colors,alpha=.25,cmap=plt.cm.seismic,norm=colors.Normalize(vmin=-1,vmax=1))\n",
        "    plt.scatter(X[0,][mal & correct],X[1,][mal & correct],marker='+',c='cyan',alpha=.35)\n",
        "    plt.scatter(X[0,][~mal & correct],X[1,][~mal & correct],marker='_',c=\"orange\",alpha=.35)\n",
        "    plt.scatter(X[0,][mal & ~correct],X[1,][mal & ~correct],marker='+',c='cyan')\n",
        "    plt.scatter(X[0,][~mal & ~correct],X[1,][~mal & ~correct],marker='_',c='orange')\n",
        "  else:\n",
        "    size=np.sqrt(size)*X.shape[1]*3\n",
        "    plt.scatter(grid[0,],grid[1,],marker='.',c=grid_colors,alpha=.25,cmap=plt.cm.seismic,norm=colors.Normalize(vmin=-1,vmax=1))\n",
        "    plt.scatter(X[0,][mal & correct],X[1,][mal & correct],marker='+',c='cyan',alpha=.35,s=size[mal & correct])\n",
        "    plt.scatter(X[0,][~mal & correct],X[1,][~mal & correct],marker='_',c=\"orange\",alpha=.35,s=size[~mal & correct])\n",
        "    plt.scatter(X[0,][mal & ~correct],X[1,][mal & ~correct],marker='+',c='cyan',s=size[mal & ~correct])\n",
        "    plt.scatter(X[0,][~mal & ~correct],X[1,][~mal & ~correct],marker='_',c='orange',s=size[~mal & ~correct])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JY3QQ4gKHbh"
      },
      "source": [
        "correct_train=(y_train==dtm.predict(X_train.T))\n",
        "error_scatter(X_train,mal_train,correct_train,grid,grid_colors)\n",
        "print_prec_and_recall(y_train,dtm.predict(X_train.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHd9iXNaMCzS"
      },
      "source": [
        "correct_test=(y_test==dtm.predict(X_test.T))\n",
        "error_scatter(X_test,mal_test,correct_test,grid,grid_colors)\n",
        "print_prec_and_recall(y_test,dtm.predict(X_test.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kqm91mlfDCC"
      },
      "source": [
        "We can see here that the precision and recall are around 70% for the unseen data. (Unless it's not, again, I missed some randomization somewhere...) Maintaining this model, is there a way we can improve the recall? If we can, what effect will this have on the precision?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPojVh65hmgi"
      },
      "source": [
        "#####Answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9MzHB8Phobt"
      },
      "source": [
        "#We can change the threshold that we classify points\n",
        "#IE: we will classify as malignant if more than 20% of points on a leaf are malignant\n",
        "threshold_classification=((dtm.predict_proba(X_test.T)[:,1]>.2)-.5)*2\n",
        "correct_test=np.array(y_test==threshold_classification)\n",
        "error_scatter(X_test,mal_test,correct_test,grid,grid_colors)\n",
        "print_prec_and_recall(y_test,threshold_classification)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSmgUU2-MCXr"
      },
      "source": [
        "#AdaBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxL99rtEOzxz"
      },
      "source": [
        "Adaptive Boosting builds on decision tree classification by taking away most of the tree. AdaBoost instead consists of a large set of decision stumps (a single data split) that are built sequentially to target incorrectly classified data, and weighted according to their accuracy. The algorithm proceeds as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14dJo0fEO1PS"
      },
      "source": [
        "To create a set of $T$ decision stumps to classify $x$, a set of $n$ data points\n",
        "\n",
        "Initialize:\n",
        "* Assign each point a *data weight* $\\alpha_i=\\frac{1}{n}$.\n",
        "\n",
        "for $t$ in $[1,2,...,T]$:\n",
        "*   Learn a decision stump $\\hat f_t(x)$\n",
        "* Calculate the $WeightedError$\n",
        "\n",
        "$$WeightedError = \\frac{\\sum_{i=1}^n\\alpha_i\\mathbb{I}_{\\hat f_t(x_i)\\neq y_i}}{\\sum_{i=1}^n\\alpha_i}$$\n",
        "\n",
        "*   Set the *model weight* according to the weighted error\n",
        "$$\\hat{w}_t=\\frac{1}{2}ln\\left(\\frac{1-WeightedError(\\hat{f}_t)}{WeightedError(\\hat{f}_t)}\\right)$$\n",
        "\n",
        "* Update the *data weights* $\\alpha$, shrinking weight on those correctly classified and raising it on the points that are incorrectly classified. (We can get clever with our indicator function, something that will come in handy when coding, note that $2(\\mathbb{I}_{\\hat f_t(x_i)=y_i}-.5)$ is +1 for incorrectly classified data, and -1 for correctly classified data.)\n",
        "\n",
        "$$\\alpha_i=\\alpha_ie^{2(\\mathbb{I}_{\\hat f_t(x_i)\\neq y_i}-.5)\\hat{w}_t}$$\n",
        "\n",
        "To avoid the weights becoming too extreme and causing numerical issues with computation, they can be renormalized each run. \n",
        "\n",
        "To make predictions we take \n",
        "\n",
        "$$\\hat{y}=\\hat{F}(x)=sign\\left(\\sum_{t=1}^T\\hat{w}_t\\hat{f}_t(x)\\right)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohAUyPGarSgu"
      },
      "source": [
        "Because the AdaBoost algorithm doesn't let you see things like *data weights* as the model is fitting, I wrote my own. Let's work through the code together.\n",
        "\n",
        "<sup><sub>\n",
        "There may be an error in the code below, in which case you can find the error as an extra exercise. If there isn't an error, then doublechecking it was the exercise. In either case, it was definitely intentional.</sup></sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqMLxhPo3zHn"
      },
      "source": [
        "######Hide Large Code Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdVv0-WcBp0l"
      },
      "source": [
        "class AdaBoostManual:\n",
        "  def __init__(self, num_trees, X, y):\n",
        "    self.stumps=[DecisionTreeClassifier(max_depth=1,random_state=i) for i in range(num_trees)]\n",
        "    self.data_weights=np.zeros((num_trees,X.shape[1]))\n",
        "    self.model_weights=np.zeros(num_trees)\n",
        "    self.X=X\n",
        "    self.y=y\n",
        "    self.num_trees=num_trees\n",
        "    self.stump_predictions=np.zeros((num_trees,X.shape[1]))\n",
        "    self.predictions=np.zeros((num_trees,X.shape[1]))\n",
        "    self.psuedoprob=np.zeros((num_trees,X.shape[1]))\n",
        "    #I just like to save lots of stuff in case I want to use it later.\n",
        "\n",
        "  def train(self):\n",
        "    #Initialize for the first tree - data weights are equal.\n",
        "    self.data_weights[0]=1/self.X.shape[1]\n",
        "    #The decision stump is fit and a number of variables are saved\n",
        "    self.stumps[0].fit(self.X.T,self.y)\n",
        "    self.stump_predictions[0]=self.stumps[0].predict(self.X.T)\n",
        "    self.predictions[0]=self.stump_predictions[0]\n",
        "    self.psuedoprob[0]=self.stump_predictions[0]\n",
        "    #We calculate the errors for this model\n",
        "    errors=np.array([t for t in self.predictions[0]!=self.y])\n",
        "    #Which we use to calculate the weighted error (unweighted for the first stump)\n",
        "    WeightedError=np.sum(errors)/self.X.shape[1];\n",
        "    #We assign the model weight according to the weighted error\n",
        "    self.model_weights[0]=0.5*np.log((1-WeightedError)/WeightedError)\n",
        "    #We use the errors to adjust the weights, the variable\n",
        "    self.data_weights[0]=self.data_weights[0]*np.exp((errors-.5)*2*self.model_weights[0])\n",
        "    #Lastly, we normalize\n",
        "    self.data_weights[0]=self.data_weights[0]/self.data_weights[0].sum()\n",
        "    for i in range(1,self.num_trees):\n",
        "      self.stumps[i].fit(self.X.T,self.y,sample_weight=self.data_weights[i-1])\n",
        "      self.stump_predictions[i]=self.stumps[i].predict(self.X.T)\n",
        "      #Predictions at each stage are constructed from weighted sums of the previous models\n",
        "      for j in range(i):\n",
        "        self.predictions[i]=self.predictions[i]+self.model_weights[j]*self.stump_predictions[j]\n",
        "      self.psuedoprob[i]=self.predictions[i]/np.max(np.abs(self.predictions[i]))\n",
        "      #We take the sign of the resulting sum as the predicted value\n",
        "      self.predictions[i]=np.sign(self.predictions[i])\n",
        "      errors=np.array([t for t in self.stumps[i].predict(self.X.T)!=self.y])\n",
        "      WeightedError=np.sum(errors*self.data_weights[i-1])/self.data_weights[i-1].sum();\n",
        "      #Then we again assign the model weight and update data weights\n",
        "      self.model_weights[i]=0.5*np.log((1-WeightedError)/WeightedError)\n",
        "      self.data_weights[i]=self.data_weights[i-1]*np.exp((errors-.5)*2*self.model_weights[i])\n",
        "      self.data_weights[i]=self.data_weights[i]/self.data_weights[i].sum()\n",
        "\n",
        "  def predict(self,X_test,early_stop=None):\n",
        "    preds=np.zeros(X_test.shape[1])\n",
        "    if early_stop==None:\n",
        "      for i in range(self.num_trees):\n",
        "        tmp=self.stumps[i].predict(X_test.T)\n",
        "        preds=preds+tmp*self.model_weights[i]\n",
        "    else:\n",
        "      for i in range(early_stop):\n",
        "        tmp=self.stumps[i].predict(X_test.T)\n",
        "        preds=preds+tmp*self.model_weights[i]\n",
        "    preds=np.sign(preds)\n",
        "    return(preds)\n",
        "\n",
        "  #This is not a true probability, but instead returns a value between -1 and 1.\n",
        "  def psuedoprobpredict(self,X_test,early_stop=None):\n",
        "    preds=np.zeros(X_test.shape[1])\n",
        "    if early_stop==None:\n",
        "      for i in range(self.num_trees):\n",
        "        tmp=self.stumps[i].predict(X_test.T)\n",
        "        preds=preds+tmp*self.model_weights[i]\n",
        "    else:\n",
        "      for i in range(early_stop):\n",
        "        tmp=self.stumps[i].predict(X_test.T)\n",
        "        preds=preds+tmp*self.model_weights[i]\n",
        "    preds=preds/np.max(np.abs(preds))\n",
        "    return(preds)\n",
        "\n",
        "ABE=AdaBoostManual(25, X_train, y_train)\n",
        "ABE.train()\n",
        "\n",
        "grid=np.meshgrid(np.arange(-.5,3.2,.01),np.arange(2.4,4.0,.01))\n",
        "grid=np.vstack((grid[0].flatten(),grid[1].flatten()))\n",
        "\n",
        "def AdaBoostViewExample(num_trees):\n",
        "  out=-ABE.psuedoprobpredict(grid,num_trees)\n",
        "\n",
        "  correct_train=(y_train==ABE.predictions[num_trees-1])\n",
        "  error_scatter(X_train,mal_train,correct_train,grid,out,size=ABE.data_weights[num_trees-1])\n",
        "  print_prec_and_recall(y_train,ABE.predictions[num_trees-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9RDTSPE33wp"
      },
      "source": [
        "######Let's look at how weights are changing from run to run\n",
        "\n",
        "The plots produced by the function $AdaBoostViewExample(k)$ show how the points are being classified after the first $k$ trees. The size of a point is proportional to the weight of the point after the $k$th tree, with the incorrectly classified points emphasized. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqZoD4COcXGd"
      },
      "source": [
        "#Input number between 1 and 24 to see how the classifier is classifying, and weighting points \n",
        "AdaBoostViewExample(25) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpGGFSJm-tVq"
      },
      "source": [
        "#Input number between 1 and 24 to see how the classifier is classifying, and weighting points \n",
        "AdaBoostViewExample(2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LF0aVCDsucK"
      },
      "source": [
        "The *sklearn* library of course has its own AdaBoost algorithm, capable of either classification or regression. Much easier than writing your own, though it does not give quick and easy access to some of the parameters (such as the model or data weights). \n",
        "\n",
        "Question for discussion - how do we do regression in AdaBoost?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR0ck5uccBwT"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "abc=AdaBoostClassifier(n_estimators=25, random_state=1)\n",
        "abc.fit(X.T, y)\n",
        "\n",
        "abc_pred=abc.predict_proba(grid.T).T[0]\n",
        "#training data\n",
        "correct_train=(y_train==abc.predict(X_train.T))\n",
        "error_scatter(X_train,mal_train,correct_train,grid,(abc_pred-.5)*2)\n",
        "print_prec_and_recall(y_train,abc.predict(X_train.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wls2dYeyz168"
      },
      "source": [
        "#testing data\n",
        "correct_test=(y_test==abc.predict(X_test.T))\n",
        "error_scatter(X_test,mal_test,correct_test,grid,(abc_pred-.5)*2)\n",
        "print_prec_and_recall(y_test,abc.predict(X_test.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkkTlJnatsrV"
      },
      "source": [
        "We can even look at the stagewise predictions for only the first $k$ models, but the access is somewhat clunky. Below is the 10th model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYWJun6AZ17n"
      },
      "source": [
        "for i, t in enumerate(abc.staged_predict_proba(grid.T)):\n",
        "  if(i==10):\n",
        "    adacolors=plt.cm.seismic(t.T[0])\n",
        "    plt.scatter(grid[0,],grid[1,],marker='.',c=adacolors,alpha=.25)\n",
        "    plt.scatter(X[0,][mal],X[1,][mal],marker='+',c='cyan')\n",
        "    plt.scatter(X[0,][~mal],X[1,][~mal],marker='_',c='orange')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS2aeyR6uxzF"
      },
      "source": [
        "#Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFEbe-7pvQHd"
      },
      "source": [
        "Random Forests attempt to improve upon decision trees by adding more trees. (Which sounds way better than taking away most of the tree, personally speaking)\n",
        "\n",
        "To produce a variety of trees from a single data set, we use bootstrap sampling to create a unique size $n$ data set sampled with replacement from the original data. In effect, this weights each point by a multiple of $\\frac{1}{n}$, in accordance with the number of times it has been sampled. Similarly, you can randomly select features on which to construct the trees, producing a wider variety of trees that are able to produce a complex decision boundary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7cga4FgvQe5"
      },
      "source": [
        "#####Random Forrest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1FRlUCSvSoA"
      },
      "source": [
        "<img src=\"https://occ-0-2794-2219.1.nflxso.net/dnm/api/v6/E8vDc_W8CLv7-yMQu8KMEC7Rrr8/AAAABRH4YM-SODj1fGal_ylc15ebTe90p_j_WPiMUjXpRGFZqMdCtc7zSFJe9C2OliUhCGmyu0APQWKZ3Q6CzAGSA8_D26Sj.jpg\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHS97QsozBxn"
      },
      "source": [
        "####Random Forest in *sklearn*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g68UYA-BzKH8"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc=RandomForestClassifier(n_estimators=25, random_state=1, max_depth=6)\n",
        "#When I type in rfc google colab autocompletes to RandomForestClassifier\n",
        "# and I just think that's neat.\n",
        "rfc.fit(X.T, y)\n",
        "\n",
        "rfc_pred=abc.predict_proba(grid.T).T[0]\n",
        "#Train data\n",
        "correct_train=(y_train==rfc.predict(X_train.T))\n",
        "error_scatter(X_train,mal_train,correct_train,grid,(rfc_pred-.5)*2)\n",
        "print_prec_and_recall(y_train,rfc.predict(X_train.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsfw5XQy1HnS"
      },
      "source": [
        "#Test data\n",
        "correct_test=(y_test==rfc.predict(X_test.T))\n",
        "error_scatter(X_test,mal_test,correct_test,grid,(rfc_pred-.5)*2)\n",
        "print_prec_and_recall(y_test,rfc.predict(X_test.T))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}